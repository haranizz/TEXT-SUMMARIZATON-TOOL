# TEXT-SUMMARIZATON-TOOL

COMPANY : CODTECH IT SOLUTIONS

NAME : HARANI C

INTERN ID : CT04DF167

DOMAIN : ARTIFICIAL INTELLIGENCE

DURATION : 4 WEEKS

MENTOR : NEELA SANTHOSH KUMAR

# DESCRIPTION OF TASK 1 - TEXT SUMMARIZATION TOOL #

Task 1 involved building a Text Summarization Tool using Natural Language Processing (NLP) techniques. The objective was to create a Python script capable of processing long articles or paragraphs and generating concise summaries that preserve the key points and ideas. This task is crucial in many real-world applications, such as summarizing news articles, research papers, or legal documents where quickly understanding the essence of a large body of text is essential.

 # Tools and Libraries Used:
To accomplish this task, I used the following libraries and technologies:

1.Python: The entire project is developed using Python, a popular and powerful language for data science and NLP tasks due to its wide range of libraries and simplicity.

2.nltk (Natural Language Toolkit): I used the nltk library to download and utilize the punkt tokenizer. This tokenizer is essential for splitting the text into sentences, which is a prerequisite for any text summarization technique.

3.Sumy Library: The core summarization was done using the sumy Python library. This library provides multiple summarization algorithms, and I used the Latent Semantic Analysis (LSA) summarizer. LSA is an unsupervised algorithm that uses mathematical techniques like Singular Value Decomposition (SVD) to identify the most important sentences based on semantic content.

4.PlaintextParser and Tokenizer: Provided by the sumy library, these components help parse raw text and prepare it for summarization. PlaintextParser reads and structures the input text, while Tokenizer divides it into processable tokens.

# How It Works:
The summarizer works by first taking a large block of text (in this case, an article on Artificial Intelligence) and breaking it into sentences. The PlaintextParser and Tokenizer perform this segmentation. After tokenization, the LsaSummarizer algorithm processes the sentences to identify the most relevant ones. It evaluates the importance of each sentence by analyzing word frequency, sentence relationships, and latent semantic structure.

The final summary is generated by selecting the top N most relevant sentences. In my implementation, I set sentence_count=3, meaning the summarizer returns the top 3 key sentences from the input text.

# Sample Execution:
The script is designed to be run as a standalone program. When executed:

It displays the original word count.

Then it prints a concise summary with the specified number of sentences.

The result clearly demonstrates how the long input paragraph has been reduced to a few meaningful lines that retain the core message.

This makes the tool very useful for readers who want to get a quick overview of lengthy content without reading the full article.

# Features:
Fully functional and minimal Python script.

Easy to modify (users can change input text and number of summary sentences).

Lightweight (uses only essential libraries).

Accurate results using the LSA summarization technique.

# Conclusion:
This task helped me understand how text summarization works under the hood, and how different NLP tools can be integrated to process and reduce large text bodies meaningfully. The solution is efficient, beginner-friendly, and serves as a solid foundation for building more advanced summarization tools using deep learning models like BART or T5 in future tasks.

This tool can be extended further by:

Allowing file input/output.

Integrating a GUI for user interaction.

Deploying it as a web application using Flask or Streamlit.

# OUTPUT #
![image](https://github.com/user-attachments/assets/e2469dc1-944a-4ebd-8c05-70235f156259)



